\documentclass[14pt,a4paper]{extarticle}

% -------------------------------
% БАЗОВІ ПАКЕТИ ТА МОВА
% -------------------------------
\usepackage{cmap} % Додано для коректного кодування шрифтів
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[ukrainian]{babel}

% -------------------------------
% ШРИФТ: Times New Roman (Повна підтримка кирилиці)
% -------------------------------
\usepackage{tempora}
\usepackage{newtxmath}

% -------------------------------
% ГЕОМЕТРІЯ СТОРІНКИ
% -------------------------------
\usepackage[
  left=1in,
  right=1in,
  top=1in,
  bottom=1in
]{geometry}

% -------------------------------
% МІЖРЯДКОВИЙ ІНТЕРВАЛ
% -------------------------------
\usepackage{setspace}
\setstretch{1.15}

% -------------------------------
% АБЗАЦИ
% -------------------------------
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt}

% -------------------------------
% ВИРІВНЮВАННЯ
% -------------------------------
\usepackage{microtype}

% -------------------------------
% ЗАГОЛОВКИ
% -------------------------------
\usepackage{titlesec}

\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}

\titleformat{\section}
  {\bfseries\large}        
  {РОЗДІЛ \thesection.} 
  {1em}
  {}

\titleformat{\subsection}
  {\bfseries\normalsize}     
  {\thesubsection.}     
  {1em}
  {}
  
% -------------------------------
% МАТЕМАТИКА
% -------------------------------
\usepackage{amsmath, amssymb}

% -------------------------------
% ЗОБРАЖЕННЯ
% -------------------------------
\usepackage{graphicx}
\usepackage{caption}

\captionsetup{
  justification=centering,
  labelsep=space,
  name=рис.
}

% =====================================================
% ГІПЕРПОСИЛАННЯ ТА ІНТЕРАКТИВНІСТЬ
% =====================================================
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=cyan,  
    citecolor=cyan,
    urlcolor=cyan,
    bookmarksnumbered=true
}
\urlstyle{same}

% Команда для синіх квадратних дужок (після підключення biblatex)
% \renewcommand{\mkbibbrackets}[1]{\textcolor{cyan}{[#1]}}

% Команда для синіх посилань на рисунки: \figref{label}
\newcommand{\figref}[1]{\hyperref[#1]{(рис. \ref*{#1})}}

% Команда для синіх посилань на розділи: \secref{label}
\newcommand{\secref}[1]{\hyperref[#1]{(розділ \ref*{#1})}}

% =====================================================
% ВИКОРИСТАНІ ДЖЕРЕЛА
% =====================================================
\usepackage[
    backend=biber,
    style=gost-numeric,
    language=ukrainian,
    citestyle=gost-numeric
]{biblatex}

\addbibresource{sources.bib}

% Команда для синіх квадратних дужок
% (визначена у biblatex; перевизначаємо після його підключення)
\renewcommand{\mkbibbrackets}[1]{\textcolor{cyan}{[#1]}}

% =====================================================
% ЗМІСТ
% =====================================================
\usepackage{tocloft}
\setlength{\cftbeforesecskip}{6pt}

% -------------------------------
% ПОЧАТОК ДОКУМЕНТА
% -------------------------------
\begin{document}

% =====================================================
% ТИТУЛЬНИЙ ЛИСТ
% =====================================================
\begin{titlepage}
\begin{center}
МІНІСТЕРСТВО ОСВІТИ І НАУКИ УКРАЇНИ\\
\vspace{0.5em}
\textbf{НАЗВА УНІВЕРСИТЕТУ}\\
\vspace{0.5em}
Кафедра \rule{6cm}{0.4pt}

\vspace{5em}

\textbf{КУРСОВА РОБОТА}\\
\vspace{0.5em}
з дисципліни \rule{8cm}{0.4pt}

\vspace{3em}

\textbf{Тема:}\\
\vspace{0.5em}
\textbf{Розробка та дослідження узагальнених суфіксних дерев у багатопотоковому середовищі Node.js}

\vspace{5em}
\end{center}

\begin{flushright}
Виконав(ла): студент(ка) \rule{4cm}{0.4pt}\\
Група \rule{3cm}{0.4pt}

\vspace{1em}

Керівник: \rule{5cm}{0.4pt}
\end{flushright}

\vfill
\begin{center}
Київ -- 2026
\end{center}
\end{titlepage}

% =====================================================
% ЗМІСТ
% =====================================================
{ \hypersetup{linkcolor=black} \tableofcontents }
\newpage

% =====================================================
% ВСТУП
% =====================================================
\section*{ВСТУП}
\addcontentsline{toc}{section}{ВСТУП}

\newpage

% =====================================================
% РОЗДІЛ 1
% =====================================================
\section{ТЕОРЕТИЧНІ ОСНОВИ ТА ОГЛЯД ТЕХНОЛОГІЙ}

\subsection{Суфіксні дерева та узагальнені суфіксні дерева}

\textbf{Визначення}. Суфiксне дерево – це орiєнтоване дерево, що
iндексує всi суфiкси рядка $S$ довжини $n$. Кожна внутрiшня нода такого дерева, окрiм кореневої ноди, має принаймнi двi дитини. Ребра суфiксного дерева маркуються непорожнiм пiдрядком $S$, при чому жоднi два ребра не можуть мати мiтки, що почнаються з одного й того ж символу. Кiлькiсть листiв повинна точно дорiвнювати кiлькостi суфiксiв у заданому рядку. Ключовою властивiстю суфiксного дерева є те, що конкатенацiя ребер вiд кореневої ноди до листка вiдповiдає суфiксу в $S$, а асоцiйований з цим листком iндекс $i$ вказує на початкову позицiю суфiкса $S_i$ .

Надамо більш формальне визначення вхідному рядку: 
\[
S = s_0, s_1, \ldots, s_{n-1}, \quad s_i \in \Sigma, \quad s_i \neq \$.
\]
Термінальний символ рядка, позначений символом $\$$, є унікальним і гарантує, що жоден суфікс не є префіксом жодного суфікса (властивість вільного префікса). Надалі в цій роботі будь-який рядок $S' = S\$$ вважається завершеним термінальним символом, навіть якщо він не зазначається явно.

Наприклад, для проіндесованого рядка $S = banana\$$ ~\figref{fig:png-1}, його суфіксами є $\$$, $a\$$, $na\$$, $ana\$$, $nana\$$, $anana\$$ і $banana\$$. Шляхом конкатенації міток ребер суфіксного дерева для S ~\figref{fig:png-2} від кореневої ноди до 3-індексованого листка, отримуємо підрядок $S_3=ana\$$. Або ж, шляхом від кореневої ноди до 0-індексованого рядка – вхідний рядок $S_0=banana\$$.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{images/рис. 1.png}
\caption{}
\label{fig:png-1}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{images/рис. 2.png}
\caption{}
\label{fig:png-2}
\end{figure}

З іншого боку, суфіксне дерево, побудоване з одного рядка, є частковим випадком узагальненого суфіксного дерева. 

\textbf{Визначення}. Узагальненим суфіксним деревом називають орієнтоване дерево, що індексує всі суфікси для набору рядків $T$ довжиною $k$.

Для побудови узагального суфіксного дерева усі k рядків з набору $T=\{S_1,S_2,…〖,S_k\$\}$ зливаються з використанням розмежувального символу $\#$ ($s_i \neq \#$), утворюючи суперрядок вигляду $S_1#S_2 \ldots S_K$.  Як і термінальний, розмежувальний символ $\#$  є унікальним,  і головна його функція полягає в запобіганні формуванню некоректних вхождень суфіксів, отриманих на перетині двох рядків з $T$. Для індексації суфіксів в узагальненому дереві використовується пара ($i:j$), де $i$ – номер рядка у $T$, $j$ – глобальний індекс суфікса в суперрядку. 

Доведемо на прикладі важливість злиття рядків з використанням розмежувального символу. Нехай $T=\{S_1,S_2\}$, де $S_1="Hello\$"$, $S_2="world\$"$.  В результаті прямого злиття заданих рядків $S_1$ і $S_2$ отримаємо суперрядок $S_m="Helloworld\$"$. Сканування ковзаючим вікном (TODO: референс на секцію) виявить підрядок $"low"$, який є підрядком $S_m$, але не є підрядком жодного з вхідних рядків $S_1$ або $S_2$. Врахування таких хибних підрядків приведе до побудови некоректного узагальненого суфіксного дерева, тому вважаємо нехтування розмежувальним символом неприйнятним. Правильна побудова такого дерева для суперрядка $S_m'="Hello\#world\$"$ представлена на ~\figref{fig:png-3}.  

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{images/рис. 3.png}
\caption{}
\label{fig:png-3}
\end{figure}


\subsection{Модель багатопотоковості в Node.js}

Архітектура платформи Node.js базується на однопотоковій моделі виконання (Single-threaded Event Loop), яка реалізована поверх двигуна JavaScript V8 та бібліотеки libuv. Ця модель використовує патерн «реактор» для забезпечення неблокуючого асинхронного вводу-виводу (I/O). Завдяки цьому операції, такі як мережеві запити або робота з файловою системою, делегуються системному ядру і не зупиняють виконання програми.

Проте, ця архітектура має критичний недолік при виконанні обчислювально-інтенсивних (CPU-bound) задач. Оскільки весь JavaScript-код виконується в одному потоці, тривалі операції — такі як побудова суфіксних дерев — повністю блокують цикл подій (Event Loop). У цьому контексті блокування означає, що Node.js не може обробляти жодні інші запити чи події, доки не завершиться поточне обчислення. Враховуючи, що алгоритм DGST передбачає складні математичні операції над великими масивами даних, використання стандартної однопотокової моделі Node.js є неефективним і призводить до повної зупинки системи~\cite{casciaro_welcome_2016}.

Одним з наївних рішень для такої проблеми є використання дочірних процесів. Реалізовані в модулі child\_processes, дочірні процеси дозволяють виконувати важкі, блокуючі операції в окремих процесах оперативної системи (ОС), не зупиняючи основний цикл подій. Вони забезпечують реальну багатопроцесорність, де кожен процес має свій екземпляр v8, пам'ять та ресурси ЦП. Хоча з першого погляду таке рішення здається ефективним, навіть офіційна документація Node.js зазначає, що створювати велику кількість дочірніх процесів через необхідність виділення додаткових ресурсів не рекомендовано [2]. Як результат, дочірні процеси є абсолютно неефективними по пам’яті.

На щастя, в Node.js v10 було представлено модуль \textbf{worker\_threads} [2]. На відміну від дочірних процесів, воркери з worker\_threads працюють всередині одного процесу ОС, але виконуються в різних потоках. Кожен воркер має окремий v8 isolate, пам’ять та цикл подій. Основним каналом комунікації між головним потоком і воркером виступає messagePort. Обмін повідомленням відбувається у дві фази: відправка повідомлення, представлена подією postMessage, і відповідно його отримання, представлене подією onMessage. Слід зазначити, що в залежності від типу даних, які пересилаються, Node.js застосовує три принципово різних механізми.

Для більшості структур, таких як масиви, мапи та рядки,  застосовується глибоке копіювання (structured clone) [3]. Тоді при передачі між потоками дані серіалізуються, одержувач отримує повну копію переданого об’єкта, а надсилач залишає собі оригінальну копію. До того ж, зміни, застосовані до переданого об’єкту, не застосовуються до оригінального. Відразу можна побачити, що для великих обсягів даних такий підхід не є оптимальним.  Натомість, механізм передачі прав на володіння (transferring)— це спосіб передачі даних між основним потоком і воркерами, при якому дані не копіюються, а буквально «переміщуються» з одного контексту в інший [4]. При передачі таким способом об’єкт передачі від’єднується, тобто стає непридатним для використання в потоці-відправнику. Node.js передає вказівник на цю ділянку пам’яті від одного потоку в інший. Хоча такий механізм уникає клонування даних, він накладає на розробника одне важливе обмеження: в один момент часу лише один потік має доступ до даних.

Щоб розв’язати цю проблему, необхідно згадати про ще одну унікальну властивість воркерів – здатність до використання \textbf{спільної пам’яті}, яку програмно реалізує \textbf{SharedArrayBuffer} \secref{sec:sharedArrayBuffer} [2].
 


\subsection{Механізм роботи SharedArrayBuffer}
\label{sec:sharedArrayBuffer}
Об’єкт SharedArrayBuffer (далі – SAB) – є фундаментальним примітивом у мові JavaScript, який дозволяє резервувати фіксований блок двійкових даних у фізичній пам’яті. 

Ключовою особливістю SAB є те, що він реалізує модель спільної пам’яті. Коли примірник SAB передається від основного потоку до воркера через метод postMessage(), середовище виконання не виконує операцію клонування даних. Замість цього, воркер отримує посилання на той самий блок фізичної пам’яті, що й основний потік. Це дозволяє двом або більше потокам читати та записувати дані в одну й ту ж ділянку пам’яті без накладних витрат на серіалізацію, десеріалізацію та виділення додаткової RAM, що є критично важливим для обробки великих даних.

Сам по собі SAB не надає методів для маніпуляції даними; він виступає лише контейнером для «сирих» байтів. Для читання або запису двійкових даних використовують \textbf{типізовані масиви} (TypedArrays), які надбудовують над буфером так званий об’єкт «представлення» (view). Різні представлення дозволяють інтерпретувати одну й ту саму послідовність байтів по-різному:
\begin{enumerate}
    \item Int8Array – як 32-бітні цілі числа зі знаком;
    \item Float64Array – як числа з плавоючою крапкою подвійної точності;
    \item Uint8Array – як 8-бітні цілі числа без знака.
\end{itemize}

У контексті цієї роботи, де основним завданням є обробка текстових даних, як основне представлення даних було обрано Uint8Array. Цей вибір зумовлюється природою вхідних даних та зручністю адресації окремих символів.
\begin{enumerate}
    \item Для мінімального представлення текстових даних, закодованих в UTF-8 (ASCII), достатньо інтерпретувати кожен символ як послідовність з 8 бітів. Використання представлень більшої розрядності призвело б до надлишкового використання пам’яті.
    \item Представлення в UInt8Array дозволяє ефективно звертатися до кожного окремого символа без додаткових обчислень зміщень за простою формулою Адреса = Початок + Індекс в масиві.
\end{itemize}

Робота в багатопотоковому середовищі, де кілька воркерів мають одночасний доступ до спільної ділянки пам’яті, неминуче створює ризик конфліктів синхронізації. \textbf{Atomics} – це глобальний об’єкт JavaScript, який надає функціонал для виконання неподільних (атомарних) операцій в спільному просторі, такі як зчитування, запис, модифікація та логічні операції. 

Проте, слід зазначити, що нюанси розробленої в цій роботі архітектури повністю виключають необхідність використання Atomics через специфічну стратегію розділення даних. Відповідно до DGST алгоритму, фаза Data Partitioning (TODO: секція) передбачає рівномірне нарізання основного масиву даних, збережених в SAB, на частини (спліти), які потім розподіляються між потоками. Як результат, кожен воркер отримує ізольовану ділянку пам’яті, яку він лише читає або модифікує локально. Таким чином, жодні два воркери не пишуть ту саму ділянку SAB, виключаючи можливість «стану гонитви».

% =====================================================
% РОЗДІЛ 2
% =====================================================
\section{ПРОЕКТУВАННЯ ТА АРХІТЕКТУРА СИСТЕМИ}

\subsection{Адаптація архітектури DGST}
Оригінальний алгоритм DGST реалізований на платформі \textbf{Apache Spark}, яка є стандартом де-факто для розподіленої обробки великих даних. Більшість проміжних обчислень у Spark виконуються в оперативній пам’яті (in-memory підхід), що надає фреймворку численні переваги над конкурентами у швидкості, простоті використання, модульності та масштабованості [5]. 

На високому рівні архітектура Spark-застосунку складається з керуючого вузла (Driver Node), який координує виконання завдань, та кластера виконавчих вузлів (Executor Nodes), що здійснюють паралельну обробку даних, збережених у розподіленій файловій системі (HDFS). Архітектура HDFS також наслідує модель «майстер-раб» (Master-Slave). Вона складається з одного головного вузла імен (NameNode), який керує метаданими файлової системи, та множини вузлів даних (DataNodes), які безпосередньо зберігають блоки інформації. HDFS організовує дані за принципом механічного поділу на блоки фіксованого розміру (зазвичай 64 МБ), які розділяються між вузлами кластера [6]. У типовому Spark-кластері виконавчі вузли зазвичай розміщуються на тих самих фізичних машинах, що й вузли даних, щоб забезпечити принцип локальності даних (Data Locality) і мінімізувати мережевий трафік. Проте, коли переміщення даних є неминучим (наприклад, під час етапу Shuffle або передачі результатів керуючому вузлу), система змушена виконувати процедуру серіалізації, що є невід'ємною платою за розподілену структуру.

Не дивлячись на застосовані оптимізації, вузьким місцем архітектури Spark залишається висока вартість I/O звернень до зовнішніх накопичувачів. Такі операції типово відбуваються під час робочого процесу і включають зчитування даних з HDFS або запис даних на жорсткий диск.

Натомість, запропонована в цій роботі архітектура переносить кластерну організацію Apache Spark на Node.js стек з використанням воркерів.  Між елементами оригінальної та поданої архітектур можна побудувати таке відображення: 
\begin{enumerate}
    \item Керуючий вузол (Driver Node) \textrightarrow\ Головний потік виконання (Main Thread).
    \item Виконавчий вузол (Executor Node) \textrightarrow\ Воркер від worker\_threads.
    \item HDFS \textrightarrow\ SharedArrayBuffer.
    \item Фізичний блок даних в HDFS \textrightarrow\ Логічний спліт SharedArrayBuffer.
\end{itemize}

Незмінним для обох архітектур залишається MapReduce потік виконання. Node.js реалізація емулює три ключові фази фреймворку: Map, Shuffle, Reduce – використовуючи програмні засоби, специфічні для цієї мови програмування. 

Така структурна трансформація дозволяє зберегти перевірену часом логіку масштабування алгоритму DGST, але фундаментально змінює фізичну модель доступу до даних. Заміна розподіленої файлової системи (HDFS) на область спільної пам’яті (SharedArrayBuffer) дозволяє усунути накладні витрати на серіалізацію та мережеву передачу даних, притаманні Spark. Завдяки цьому архітектура переходить від моделі з інтенсивним вводом-виводом (I/O-bound) до моделі з ефективним використанням пам’яті (Memory-bound), що створює підґрунтя для оптимізації етапів MapReduce у середовищі Node.js.

\subsection{Стратегія управління пам'яттю}

Як згадувалося раніше, реалізація алгоритму DGST у середовищі Node.js є моделлю, продуктивність якої критично обмежена обсягом доступної оперативної пам’яті (Memory-bound). Така архітектурна специфіка зумовлює необхідність розробки ефективної стратегії керування ресурсами RAM. Відсутність чітких механізмів контролю навантаження неминуче призведе до критичної відмови системи внаслідок вичерпання пам’яті (Out-of-Memory error).

Центральним елементом стратегії є використання єдиного об’єкта Shared\-ArrayBuffer. Для всієї сукупності вхідних рядків буфер формується одноразово при ініціалізації програми з виділенням додаткових байтів на розмежувальні та термінальний символи. При передачі буфера між потоками дані не дублюються, реалізуючи притаманий SAB принцип нульового копіювання (Zero-Copy) та знімаючи накладні витрати на серіалізацію та десеріалізацію.

Подібно до Apache Spark, головний потік системи механічно нарізає SharedArrayBuffer на рівномірні спліти, обмежені парою індексів початку й логічного завершення у спільному буфері. На відміну від чистого фізичного кінця, логічний кінець включає «хвіст» — додаткові байти, що перекривають сусідній спліт і гарантують, що жоден S-префікс не буде обірваний на межі під час паралельного аналізу [7].

Критичним параметром для стабільності DGST алгоритму є ліміт пам’яті $F_m$, який визначає максимальний розмір піддерев, що будується в пам’яті воркера. Для обрахунку ліміту застосовується гібридна  евристика, яка враховує і апаратні обмеження виконавця, і розмір вхідних файлів.

Система динамічно встановлює ліміт пам’яті на основі даних про обсяги  доступної оперативної пам’яті та кількість логічних ядер процесора. Для запобігання аварійному завершенню процеса внаслідок OOM, лише 70\% вільної RAM вважаються доступними для задачі. Такий коефіцієнт обумовлений загальноприйнятими  практиками конфігурування високонавантажених систем, де ОС рекомендується залишати 20-30\% пам’яті на системні виклики та процеси [8]. До того ж, лише 40\% цієї пам’яті відводяться на зберігання вузлів суфіксного дерева, компенсуючи накладні витрати на створення проміжних структур і v8 isolate для кожного екземпляру воркера.

Фінальне значення $F_m$ задається відношенням:
\begin{equation}
F_m=\frac{memoryPerExecutor}{bytesPerSuffix,}  
\end{equation}
де параметр $bytesPerSuffix \approx 20$ байтів. Хоча об’єкти в середовищі JavaScript мають більший фізичний розмір через системні метадані [9,10], у даній моделі це число використовується як коефіцієнт логічної питомої ваги.	

Така стратегія «оптимістичного калібрування» є безпечною завдяки тому, що сумарний обсяг пам'яті, який реально алокується під структури дерева, становить 28\% від фактично вільної RAM. Це дозволяє поєднувати зручність високорівневої об'єктної моделі JavaScript із високою продуктивністю алгоритму, уникаючи надмірної фрагментації піддерев. 

Нарешті, для досягнення балансу в системі, значення $F_m$ утримується в межах від $50\ 000$ до $\frac{FileSize}{50}$. Таке обмеження виконує подвійну функцію: нижня межа захищає від створення надто малих завдань, де витрати на запуск воркера перевищують час самих обчислень, а верхня межа гарантує, що навантаження буде розподілено між потоками навіть при обробці надвеликих масивів даних. 


\subsection{Алгоритмічні етапи реалізації}

Цей підрозділ окреслює основні етапи роботи алгоритму DGST, адаптованого під архітектуру спільної пам'яті. Процес обробки даних у розробленій системі розділений на чотири основні фази, що імітують потік виконання MapReduce.

\begin{enumerate}
  \item \textit{Фаза ініціалізації та попередньої обробки}.

    Першим кроком є підготовка середовища та вхідних даних для паралельної обробки. Файлова система зчитує вхідні рядки та передає їх до Основного потоку для конкатенації у суперрядок. Він популює попередньо зарезервовану у пам’яті ділянку під SharedArrayBuffer з виділенням  окремих байтів під розмежувальні символи та термінальний символ наприкінці. 
    Додатково, Основний потік керує динамічним визначенням кількості воркерів та обчисленням порогового значення $F_m$. У тому ж місці одноразово створюється пул для обрахованої кількості воркерів, усуваючи накладні витрати на керування їхнім життєвим циклом.

    Подальший етап передбачає рівномірне нарізання сформованого SAB на фрагменти, які називатимемо сплітами. Спліт не зберігає повний підрядок у нативному вигляді; його межі визначають індекс початку, фізичного і логічного закінчення.  Щоб жоден префікс не обірвався на межі, логічне закінчення розширюється на хвіст, але не виходить за фізичну довжину SAB.  Формування сплітів завершує підготовчу фазу потоку виконання. 

  \item \textit{Фаза ітеративного розбиття на S-префікси.}

    Метою цього етапу є пошук такого набору S-префіксів довжиною ковзного вікна $windowSize$, щоб частота кожного унікального префікса не перевищувала встановлений ліміт $F_m$. Це гарантує, що будь-яке піддерево, побудоване на основі такого префікса, вміститься в оперативну пам'ять окремого воркера. 

    Процес розбиття реалізовано як ітеративний цикл, що триває до досягнення умови $R = \varnothing$, де $R$ — множина «проблемних» префіксів, частота яких все ще перевищує поріг $F_m$. Кожна ітерація цієї фази включає наступні кроки:

    \begin{enumerate}
      \item \textbf{Паралельне сканування (Map).} Основний потік розподіляє між воркерами спліти SharedArrayBuffer, розширені на хвіст довжиною $windowSize – 1$. Виконавчі вузли отримують параметри вікна та фільтр префіксів, після чого здійснюють обхід буфера методом ковзного вікна. Для оптимізації обчислень кожен воркер будує локальний \textbf{частотний бор} (\textbf{Frequency Trie}). Використання цієї ієрархічної структури дозволяє ефективно групувати спільні префікси та виконувати підрахунок частот входжень за один прохід по тексту, 
      мінімізуючи витрати оперативної пам'яті [7].

      \item \textbf{Тасування (Shuffle).} Головним завданням даного етапу є логічне групування локальних результатів за ключовими ознаками — унікальними S-префіксами. Для забезпечення детермінованості розподілу даних використовується механізм хешування: для кожного S-префікса обчислюється хеш-код, що гарантує спрямування всіх його входжень, виявлених різними воркерами, до єдиного обчислювального контексту.

      \item \textbf{Глобальна агрегація (Reduce).} Воркери повертають Основному потоку лише компактні об'єкти з локальною статистикою частот. Головний потік агрегує ці дані, формуючи глобальну картину розподілу суфіксів. 

      \item \textbf{Перевірка умови зупинки.} На основі отриманої карти частот Основний потік будує фінальне частотний бор і аналізує його на предмет «проблемних» префіксів:
      \begin{enumerate}
        \item Префікси, частота яких $\le F_m$, заносяться до множини валідних префіксів $P$.
        \item Префікси з частотою $> F_m$ заносяться до множини «проблемних» префіксів $R$.
        \item Якщо $R \ne \varnothing$, значення $windowSize$ збільшується на $window\-StepSize$, і цикл повторюється лише для сегментів даних, що відповідають префіксам з $R$.
        \item Якщо $R = \varnothing$, цикл зупиняється. Основний потік відсікає в частотному борі надлишкові гілки і формує фінальну карту частот префіксів.
      \end{enumerate}
    \end{enumerate}
      
  \item \textit{Фаза розподілу завдань. }

  Ключовим завданням даного етапу є запобігання виникненню «вузьких  місць» (bottlenecks), що спричинені нерівномірним розподілом обчислювального навантаження між воркерами. Цю проблему вирішує комбінований підхід на основі двох алгоритмів: \textbf{Bin-Packing} та \textbf{Number Partitioning}. Їхня спільна робота спрямована на формування мінімально необхідної кількості груп завдань, де сумарна частота S-префіксів у кожній групі є максимально наближеною. Оскільки кількість груп завдань часто перевищує кількість доступних виконавчих вузлів, їхня паралельна обробка виконується послідовно по раундах. Такий підхід забезпечує рівномірне навантаження всіх потоків виконання та синхронне завершення обробки даних.

  \item \textit{Фаза побудови піддерев.}

  У результаті завершення фази розподілу навантаження кожен воркер отримує індивідуальний пакет завдань, що складається з набору валідних S-префіксів. Кожен префікс із цього набору є коренем майбутнього суфіксного піддерева, яке гарантовано вміщується в оперативну пам’ять окремого воркера. Принцип побудови піддерев базується на методі SALA (Suffix Array + LCP Array).

  \textbf{Суфіксний масив (SA)} є фундаментальною структурою даних, що впорядковує всі суфікси вхідного рядка у лексикографічному порядку. Оскільки операція сортування такого великого масиву є найбільш ресурсомісткою частиною алгоритму, для її прискорення використовується структура \textbf{LCP-Range} — трійка, яка зберігає інформацію про вже знайдені спільні частини рядків (Longest Common Prefix, найдовший спільний префікс). Це дозволяє реалізувати LCP-свідоме сортування, де суфікси порівнюються не з нуля, а зі зміщенням у довжину спільного початку, що значно економить ресурси CPU та I/O.
  
  Після сортування воркер розраховує LCP для кожної пари сусідніх елементів у масиві SA. Ці значення визначають глибину вкладеності та точки розгалуження майбутнього дерева. На основі готових масивів SA та LCP воркер будує піддерево за один лінійний прохід. Використовується допоміжний стек для відстеження поточного шляху від кореня. Нові вузли та листи додаються або розрізають існуючі ребра у точках, вказаних значеннями LCP.
\end{enumerate}

Отже, після завершення обчислень Основний потік отримує результати побудови всіх груп завдань. Сукупність цих локальних піддерев утворює розподілене узагальнене суфіксне дерево. Завдяки ітеративному розбиттю та паралельній побудові, отримана структура є повністю охоплює множину суфіксів усіх вхідних рядків, що робить її готовою до практичного використання у прикладних задачах.


% =====================================================
% РОЗДІЛ 3
% =====================================================
\section{ПРОГРАМНА РЕАЛІЗАЦІЯ}

\subsection{Середовище розробки та інструменти}

\subsection{Реалізація Майстер-ноди (Main Thread)}

\subsection{Реалізація Виконавчих нод (Workers)}

\subsection{Вирішення проблем синхронізації та безпеки}

% =====================================================
% РОЗДІЛ 4
% =====================================================
\section{ЕКСПЕРИМЕНТАЛЬНЕ ДОСЛІДЖЕННЯ ТА АНАЛІЗ ЕФЕКТИВНОСТІ}

% =====================================================
% ВИСНОВКИ
% =====================================================
\section*{ВИСНОВКИ}
\addcontentsline{toc}{section}{ВИСНОВКИ}

% =====================================================
% ВИКОРИСТАНІ ДЖЕРЕЛА
% =====================================================
\newpage
\printbibliography[
    heading=bibintoc,               % Додає список у зміст (table of contents)
    title={ВИКОРИСТАНІ ДЖЕРЕЛА}     % Власний заголовок великими літерами
]

\end{document}
