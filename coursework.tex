\documentclass[14pt,a4paper]{extarticle}

% -------------------------------
% БАЗОВІ ПАКЕТИ ТА МОВА
% -------------------------------
\usepackage{cmap} % Додано для коректного кодування шрифтів
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[ukrainian]{babel}

% -------------------------------
% ШРИФТ: Times New Roman (Повна підтримка кирилиці)
% -------------------------------
\usepackage{tempora}
\usepackage{newtxmath}

% -------------------------------
% ГЕОМЕТРІЯ СТОРІНКИ
% -------------------------------
\usepackage[
  left=20mm,
  right=20mm,
  top=20mm,
  bottom=20mm
]{geometry}

% -------------------------------
% МІЖРЯДКОВИЙ ІНТЕРВАЛ
% -------------------------------
\usepackage{setspace}
\setstretch{1.5}

% -------------------------------
% АБЗАЦИ
% -------------------------------
\setlength{\parindent}{1.25cm}
\setlength{\parskip}{6pt}
\usepackage{indentfirst}

% -------------------------------
% ВИРІВНЮВАННЯ
% -------------------------------
\usepackage{microtype}
\usepackage{enumitem}
\setlist[itemize]{listparindent=\parindent, parsep=\parskip}
\setlist[enumerate]{listparindent=\parindent, parsep=\parskip}

% -------------------------------
% ЗАГОЛОВКИ
% -------------------------------
\usepackage{titlesec}

\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}

\titleformat{name=\section,numberless}
{\bfseries\large\filcenter}
{}
{0pt}
{}

\titleformat{name=\section,numberless}
{\bfseries\large\filcenter}
{}
{0pt}
{}

\titleformat{\section}
{\bfseries\large}
{РОЗДІЛ \thesection.}
{1em}
{}

\titleformat{\subsection}
{\bfseries\normalsize}
{\thesubsection.}
{1em}
{}

% -------------------------------
% МАТЕМАТИКА
% -------------------------------
% NOTE: \usepackage{amssymb} conflicts with newtxmath/amsfonts in this setup (redefines \Bbbk)
\usepackage{amsmath}
\usepackage{amsfonts}

% -------------------------------
% ЗОБРАЖЕННЯ
% -------------------------------
\usepackage{graphicx}
\usepackage[justification=centering]{caption}
\usepackage{newfloat}
\usepackage{newfloat}

\captionsetup{
  labelsep=period,
  name=рис
}
\captionsetup[table]{position=bottom}

% =====================================================
% ГІПЕРПОСИЛАННЯ ТА ІНТЕРАКТИВНІСТЬ
% =====================================================
\usepackage{xcolor}
\usepackage{csquotes}
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=cyan,
  citecolor=cyan,
  urlcolor=cyan,
  bookmarksnumbered=true
}
\captionsetup[table]{position=bottom}
\urlstyle{same}

% Команда для синіх квадратних дужок (після підключення biblatex)
% \renewcommand{\mkbibbrackets}[1]{\textcolor{cyan}{[#1]}}

% Команда для синіх посилань на рисунки: \figref{label}
\newcommand{\figref}[1]{\hyperref[#1]{(рис. \ref*{#1})}}

% Команда для синіх посилань на розділи: \secref{label}
\newcommand{\secref}[1]{\hyperref[#1]{(розділ \ref*{#1})}}

% Команда для синіх посилань на схеми: \secref{label}
\newcommand{\schemaref}[1]{\hyperref[#1]{схемі \ref*{#1}}}

% Команда для синіх посилань на таблиці: \tabref{label}
\newcommand{\tabref}[1]{\hyperref[#1]{таблиці \ref*{#1}}}

% =====================================================
% ВИКОРИСТАНІ ДЖЕРЕЛА
% =====================================================
\usepackage[
  backend=biber,
  style=numeric,
  sorting=none,
  defernumbers=true,
  maxbibnames=99,
  giveninits=true,
]{biblatex}

\addbibresource{sources.bib}

% -------------------------------------------------------
% 1. ВИПРАВЛЕННЯ МОВИ
% -------------------------------------------------------
\DefineBibliographyStrings{ukrainian}{
  andothers  = {et~al\adddot},
  and        = {and},
  in         = {in},
  urlseen    = {Accessed},
  edition    = {ed\adddot},
}

% -------------------------------------------------------
% 2. ФОРМАТ ПОЛІВ
% -------------------------------------------------------
\DeclareFieldFormat*{title}{#1}
\DeclareFieldFormat[book,inbook,incollection]{booktitle}{\mkbibemph{#1}}
\DeclareFieldFormat[article]{journaltitle}{\mkbibemph{#1}}
\DeclareFieldFormat*{titleaddon}{#1}
\DeclareFieldFormat[article]{volume}{Vol\adddot~#1}
\DeclareFieldFormat[article]{number}{(#1)}
\DeclareFieldFormat{pages}{#1}
\DeclareFieldFormat{edition}{#1}
\DeclareFieldFormat{url}{\url{#1}}

% -------------------------------------------------------
% 3. ІМЕНА: Прізвище І.
% -------------------------------------------------------
\DeclareNameAlias{default}{family-given}
\renewcommand*{\multinamedelim}{\addcomma\space}
\renewcommand*{\finalnamedelim}{\addcomma\space}
\renewcommand*{\andothersdelim}{\addspace}

% -------------------------------------------------------
% 4. URL + ДАТА ДОСТУПУ
%    Формат: URL: https://... [Accessed 27 Jan. 2026]
%    Без крапки в кінці — крапка не додається
% -------------------------------------------------------
\def\mkbibmonth#1{%
  \ifcase#1\or
    Jan\or Feb\or Mar\or Apr\or May\or Jun\or
    Jul\or Aug\or Sep\or Oct\or Nov\or Dec\fi
}

\renewbibmacro*{url+urldate}{%
  \iffieldundef{url}{}{%
    URL\addcolon\addspace
    \printfield{url}%
    \iffieldundef{urlday}{%
      \iffieldundef{urlyear}{}{%
        \addspace[Accessed\addspace\thefield{urlyear}]%
      }%
    }{%
      \addspace[Accessed\addspace
        \thefield{urlday}\addspace
        \mkbibmonth{\thefield{urlmonth}}\adddot\addspace
        \thefield{urlyear}]%
    }%
  }%
}

% -------------------------------------------------------
% 5. ДРАЙВЕР: @incollection
%    Casciaro M., Mammino L. Welcome to the Node.js Platform.
%    In: Node.js Design Patterns, 2nd Edition.
%    Packt Publishing Ltd., Birmingham, 2016, 24--31.
% -------------------------------------------------------
\DeclareBibliographyDriver{incollection}{%
  \printnames{author}%
  \setunit{\adddot\space}%
  \printfield{title}%
  \setunit{\adddot\addspace In\addcolon\space}%
  \printfield{booktitle}%
  \iffieldundef{edition}{}{%
    \setunit{\addcomma\space}%
    \printfield{edition}%
  }%
  \setunit{\adddot\space}%
  \printlist{publisher}%
  \setunit{\addcomma\space}%
  \printlist{location}%
  \setunit{\addcomma\space}%
  \printfield{year}%
  \iffieldundef{pages}{}{%
    \setunit{\addcomma\space}%
    \printfield{pages}%
  }%
  \adddot
  \usebibmacro{finentry}%
}

% -------------------------------------------------------
% 6. ДРАЙВЕР: @article
%    Xia Z. ... Journal of Information Security, Elsevier,
%    2025, Vol. 92 (7), Article 104082.
% -------------------------------------------------------
\DeclareBibliographyDriver{article}{%
  \printnames{author}%
  \setunit{\adddot\space}%
  \printfield{title}%
  \setunit{\adddot\space}%
  \printfield{journaltitle}%
  \iflistundef{publisher}{}{%
    \setunit{\addcomma\space}%
    \printlist{publisher}%
  }%
  \setunit{\addcomma\space}%
  \printfield{year}%
  \iffieldundef{volume}{}{%
    \setunit{\addcomma\space}%
    \printfield{volume}%
    \iffieldundef{number}{}{%
      \addspace\printfield{number}%
    }%
  }%
  \iffieldundef{pages}{}{%
    \setunit{\addcomma\space}%
    \printfield{pages}%
  }%
  \iffieldundef{eid}{}{%
    \setunit{\addcomma\space}%
    Article~\printfield{eid}%
  }%
  \adddot
  \usebibmacro{finentry}%
}

% -------------------------------------------------------
% 7. ДРАЙВЕР: @online
%    ПОРЯДОК: Назва сайту. Назва статті. Автор. URL: ... [Accessed ...]
%    Крапки в кінці НЕМАЄ
% -------------------------------------------------------
\DeclareBibliographyDriver{online}{%
  % 1. Назва сайту (titleaddon)
  \iffieldundef{titleaddon}{}{%
    \printfield{titleaddon}%
    \setunit{\adddot\space}%
  }%
  % 2. Назва статті (title)
  \printfield{title}%
  % 3. Автор
  \ifnameundef{author}{}{%
    \setunit{\adddot\space}%
    \printnames{author}%
  }%
  % 4. Рік (якщо є) 
  \iffieldundef{year}{}{%
    \setunit{\addcomma\space}%
    \printfield{year}%
  }%
  % 5. URL + дата доступу
  \adddot\addspace
  \usebibmacro{url+urldate}%
  % БЕЗ крапки в кінці
  \usebibmacro{finentry}%
}   

\addbibresource{sources.bib}

% Команда для синіх квадратних дужок
% (визначена у biblatex; перевизначаємо після його підключення)
\renewcommand{\mkbibbrackets}[1]{\textcolor{cyan}{[#1]}}

% =====================================================
% ЗМІСТ
% =====================================================
\usepackage{tocloft}
\setlength{\cftbeforesecskip}{6pt}
\renewcommand{\cfttoctitlefont}{\bfseries\large\hfil}
\renewcommand{\cftaftertoctitle}{\hfil}
\addto\captionsukrainian{\renewcommand{\contentsname}{ЗМІСТ}}
\renewcommand{\contentsname}{ЗМІСТ}

% =====================================================
% СНІПЕТИ КОДУ
% =====================================================
\usepackage{listings}
\usepackage{needspace}
\usepackage{float}

% Лістинги ("схеми"): робимо окремий float-тип і оточення, яке НІКОЛИ не ділиться між сторінками.
\floatstyle{plain}
\DeclareFloatingEnvironment[name=Схема]{scheme}
\floatname{scheme}{Схема}

% Визначення кольорів для синтаксису
\definecolor{lightgray}{rgb}{0.95, 0.95, 0.95}
\definecolor{darkgray}{rgb}{0.4, 0.4, 0.4}
\definecolor{purple}{rgb}{0.58, 0, 0.82}
\definecolor{blue}{rgb}{0, 0, 1}
\definecolor{green}{rgb}{0, 0.5, 0}

% Налаштування стилю для JavaScript
\lstdefinelanguage{JavaScript}{
  keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break, const, let, async, await},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkgray}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{green}\ttfamily,
  stringstyle=\color{purple}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}

\lstset{
  language=JavaScript,
  backgroundcolor=\color{lightgray},
  extendedchars=true,
  basicstyle=\footnotesize\ttfamily,
  showstringspaces=false,
  showspaces=false,
  numbers=left,
  numberstyle=\tiny\color{darkgray},
  numbersep=9pt,
  tabsize=2,
  breaklines=true,
  showtabs=false,
  captionpos=b, % Підпис під кодом
  frame=single  % Рамка навколо коду
}

\addto\captionsukrainian{%
  \renewcommand{\lstlistingname}{Схема}%
}
\captionsetup[lstlisting]{
  labelsep=period,
  justification=centering,
  singlelinecheck=false
}

\captionsetup[scheme]{
  justification=centering,
  singlelinecheck=false
}

\captionsetup[scheme]{
  justification=centering,
  singlelinecheck=false
}

% -------------------------------
% ПОЧАТОК ДОКУМЕНТА
% -------------------------------
\begin{document}

% =====================================================
% ТИТУЛЬНИЙ ЛИСТ
% =====================================================
\begin{titlepage}
  \begin{center}
    Міністерство освіти і науки України\\
    НАЦІОНАЛЬНИЙ УНІВЕРСИТЕТ «КИЄВО-МОГИЛЯНСЬКА АКАДЕМІЯ»\\
    Кафедра мережевих технологій, факультет інформатики
  \end{center}

  \vspace{2cm}

  \begin{center}
    \textbf{ОБРОБКА ДАНИХ З ВИКОРИСТАННЯМ \\
    WEBWORKERS ТА SHAREDARRAYBUFER}\\[1cm]
    \textbf{Текстова частина до курсової роботи}\\
    за спеціальністю 122 «Комп'ютерні науки»
  \end{center}

  \vspace{2cm}

  \begin{flushright}
    Керівник курсової роботи\\[0.5cm]
    Зважій Д.В.\\
    Старший викладач\\[1mm]
    \rule{5cm}{0.4pt}\\
    (підпис)\\[1mm]
    \rule{1cm}{0.4pt}~\rule{2cm}{0.4pt}~2026~р.\\[1mm]
    Виконала студентка 3-го курсу\\
    Малій О.М.\\[1mm]
    \rule{1cm}{0.4pt}~\rule{2cm}{0.4pt}~2026~р.
  \end{flushright}

  \vspace{0.8cm}

  \begin{center}
    Київ 2026
  \end{center}
\end{titlepage}

% =====================================================
% ЗМІСТ
% =====================================================
{ \hypersetup{linkcolor=black} \tableofcontents }
\newpage

% =====================================================
% АНОТАЦІЯ
% =====================================================
\section*{АНОТАЦІЯ}
\addcontentsline{toc}{section}{АНОТАЦІЯ}
\newpage

% =====================================================
% СКОРОЧЕННЯ
% =====================================================
\section*{СКОРОЧЕННЯ ТА УМОВНІ ПОЗНАЧЕННЯ}
\addcontentsline{toc}{section}{СКОРОЧЕННЯ ТА УМОВНІ ПОЗНАЧЕННЯ}

\begin{itemize}
  \item \textbf{LCP} --- Longest Common Prefix (найдовший спільний префікс)
  \item \textbf{DGST} --- Distributed Generalized Suffix Tree (розподілене узагальнене суфіксне дерево)
  \item \textbf{I/O} --- Input/Output (введення-виведення)
  \item \textbf{CPU} --- Central Processing Unit (центральний процесор)
  \item \textbf{SAB} --- SharedArrayBuffer (буфер спільної пам'яті)
  \item \textbf{RAM} --- Random Access Memory (оперативна пам'ять)
  \item \textbf{API} --- Application Programming Interface (інтерфейс програмування застосунків)
  \item \textbf{HDFS} --- Hadoop Distributed File System (розподілена файлова система Hadoop)
  \item \textbf{OOM} --- Out-of-Memory (вичерпання оперативної пам'яті)
  \item \textbf{SA} --- Suffix Array (суфіксний масив)
  \item \textbf{SALA} --- Suffix Array + LCP Array (метод побудови суфіксного дерева на основі суфіксного масиву та масиву LCP)
  \item \textbf{UTF-8} --- Unicode Transformation Format 8-bit (8-бітний формат перетворення Unicode)
  \item \textbf{KMP} --- Knuth–Morris–Pratt (алгоритм пошуку підрядка Кнута–Морріса–Пратта)
\end{itemize}

\newpage

% =====================================================
% ВСТУП
% =====================================================
\section*{ВСТУП}
\addcontentsline{toc}{section}{ВСТУП}

\newpage

% =====================================================
% РОЗДІЛ 1
% =====================================================
\section{ТЕОРЕТИЧНІ ОСНОВИ ТА ОГЛЯД ТЕХНОЛОГІЙ}

\subsection{Суфіксні дерева та узагальнені суфіксні дерева}

\textbf{Визначення}. Суфiксне дерево – це орiєнтоване дерево, що
iндексує всi суфiкси рядка $S$ довжини $n$. Кожна внутрiшня нода такого дерева, окрiм кореневої ноди, має принаймнi двi дитини. Ребра суфiксного дерева маркуються непорожнiм пiдрядком $S$, при чому жоднi два ребра не можуть мати мiтки, що почнаються з одного й того ж символу. Кiлькiсть листiв повинна точно дорiвнювати кiлькостi суфiксiв у заданому рядку. Ключовою властивiстю суфiксного дерева є те, що конкатенацiя ребер вiд кореневої ноди до листка вiдповiдає суфiксу в $S$, а асоцiйований з цим листком iндекс $i$ вказує на початкову позицiю суфiкса $S_i$ .

Надамо більш формальне визначення вхідному рядку:
\[
  S = s_0, s_1, \ldots, s_{n-1}, \quad s_i \in \Sigma, \quad s_i \neq \$.
\]
Термінальний символ рядка, позначений символом $\$$, є унікальним і гарантує, що жоден суфікс не є префіксом жодного суфікса (властивість вільного префікса). Надалі в цій роботі будь-який рядок $S' = S\$$ вважається завершеним термінальним символом, навіть якщо він не зазначається явно.

Наприклад, для проіндесованого рядка $S = banana\$$ ~\figref{fig:png-1}, його суфіксами є $\$$, $a\$$, $na\$$, $ana\$$, $nana\$$, $anana\$$ і $banana\$$. Шляхом конкатенації міток ребер суфіксного дерева для S ~\figref{fig:png-2} від кореневої ноди до 3-індексованого листка, отримуємо підрядок $S_3=ana\$$. Або ж, шляхом від кореневої ноди до 0-індексованого рядка – вхідний рядок $S_0=banana\$$.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\textwidth]{images/рис. 1.png}
  \caption{Суфіксне дерево для рядка $S=banana\$$}
  \label{fig:png-1}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{images/рис. 2.png}
  \caption{Структура суфіксного дерева для рядка $S=banana\$$}
  \label{fig:png-2}
\end{figure}

З іншого боку, суфіксне дерево, побудоване з одного рядка, є частковим випадком узагальненого суфіксного дерева.

\textbf{Визначення}. Узагальненим суфіксним деревом називають орієнтоване дерево, що індексує всі суфікси для набору рядків $T$ довжиною $k$.

Для побудови узагального суфіксного дерева усі $k$ рядків з набору $T=\{S_1,S_2,\ldots,S_k\}$ зливаються з використанням розмежувального символу $\#$ ($s_i \neq \#$), утворюючи суперрядок вигляду $S_1\#S_2\ldots S_k$. Як і термінальний, розмежувальний символ $\#$ є унікальним, і головна його функція полягає в запобіганні формуванню некоректних входжень суфіксів, отриманих на перетині двох рядків з $T$. Для індексації суфіксів в узагальненому дереві використовується пара $(i:j)$, де $i$ – номер рядка у $T$, $j$ – глобальний індекс суфікса в суперрядку.

Доведемо на прикладі важливість злиття рядків з використанням розмежувального символу. Нехай $T=\{S_1,S_2\}$, де $S_1="Hello\$"$, $S_2="world\$"$.  В результаті прямого злиття заданих рядків $S_1$ і $S_2$ отримаємо суперрядок $S_m="Helloworld\$"$. Сканування ковзаючим вікном \secref{sec:iterative} виявить підрядок $"low"$, який є підрядком $S_m$, але не є підрядком жодного з вхідних рядків $S_1$ або $S_2$. Врахування таких хибних підрядків приведе до побудови некоректного узагальненого суфіксного дерева, тому вважаємо нехтування розмежувальним символом неприйнятним. Правильна побудова такого дерева для суперрядка $S_m'="Hello\#world\$"$ представлена на ~\figref{fig:png-3}.

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{images/рис. 3.png}
  \caption{Узагальнене суфіксне дерево для суперрядка $S_m'=Hello\#world\$$}
  \label{fig:png-3}
\end{figure}

\subsection{Модель багатопотоковості в Node.js}

Архітектура платформи Node.js базується на однопотоковій моделі виконання (Single-threaded Event Loop), яка реалізована поверх двигуна JavaScript V8 та бібліотеки libuv. Ця модель використовує патерн «реактор» для забезпечення неблокуючого асинхронного вводу-виводу (I/O). Завдяки цьому операції, такі як мережеві запити або робота з файловою системою, делегуються системному ядру і не зупиняють виконання програми.

Проте, ця архітектура має критичний недолік при виконанні обчислювально-інтенсивних (CPU-bound) задач. Оскільки весь JavaScript-код виконується в одному потоці, тривалі операції — такі як побудова суфіксних дерев — повністю блокують цикл подій (Event Loop). У цьому контексті блокування означає, що Node.js не може обробляти жодні інші запити чи події, доки не завершиться поточне обчислення. Враховуючи, що алгоритм DGST передбачає складні математичні операції над великими масивами даних, використання стандартної однопотокової моделі Node.js є неефективним і призводить до повної зупинки системи~\cite{casciaro_welcome_2016}.

Одним з наївних рішень для такої проблеми є використання дочірних процесів. Реалізовані в модулі child\_processes, дочірні процеси дозволяють виконувати важкі, блокуючі операції в окремих процесах оперативної системи (ОС), не зупиняючи основний цикл подій. Вони забезпечують реальну багатопроцесорність, де кожен процес має свій екземпляр V8, пам'ять та ресурси ЦП. Хоча з першого погляду таке рішення здається ефективним, навіть офіційна документація Node.js зазначає, що створювати велику кількість дочірніх процесів через необхідність виділення додаткових ресурсів не рекомендовано ~\cite{nodejs_child_nodate}. Як результат, дочірні процеси є абсолютно неефективними по пам’яті.

На щастя, в Node.js v10 було представлено модуль \textbf{worker\_threads}~\cite{nodejs_worker_nodate}. На відміну від дочірних процесів, воркери з worker\_threads працюють всередині одного процесу ОС, але виконуються в різних потоках. Кожен воркер має окремий V8 isolate, пам’ять та цикл подій. Основним каналом комунікації між головним потоком і воркером виступає messagePort. Обмін повідомленням відбувається у дві фази: відправка повідомлення, представлена подією postMessage, і відповідно його отримання, представлене подією onMessage. Слід зазначити, що в залежності від типу даних, які пересилаються, Node.js застосовує три принципово різних механізми.

Для більшості структур, таких як масиви, мапи та рядки,  застосовується глибоке копіювання (structured clone)~\cite{mdn_web_docs_structured_nodate}. Тоді при передачі між потоками дані серіалізуються, одержувач отримує повну копію переданого об’єкта, а надсилач залишає собі оригінальну копію. До того ж, зміни, застосовані до переданого об’єкту, не застосовуються до оригінального. Відразу можна побачити, що для великих обсягів даних такий підхід не є оптимальним.  Натомість, механізм передачі прав на володіння (transferring)— це спосіб передачі даних між основним потоком і воркерами, при якому дані не копіюються, а буквально «переміщуються» з одного контексту в інший~\cite{mdn_web_docs_transferable_nodate}. При передачі таким способом об’єкт передачі від’єднується, тобто стає непридатним для використання в потоці-відправнику. Node.js передає вказівник на цю ділянку пам’яті від одного потоку в інший. Хоча такий механізм уникає клонування даних, він накладає на розробника одне важливе обмеження: в один момент часу лише один потік має доступ до даних.

Щоб розв’язати цю проблему, необхідно згадати про ще одну унікальну властивість воркерів – здатність до використання \textbf{спільної пам’яті}, яку програмно реалізує SharedArrayBuffer \secref{sec:sharedArrayBuffer}.

\subsection{Механізм роботи SharedArrayBuffer}
\label{sec:sharedArrayBuffer}
Об’єкт \textbf{SharedArrayBuffer} (далі – SAB) – є фундаментальним примітивом у мові JavaScript, який дозволяє резервувати фіксований блок двійкових даних у фізичній пам’яті~\cite{mdn_web_docs_sharedarraybuffer_nodate}.

Ключовою особливістю SAB є те, що він реалізує модель спільної пам’яті. Коли примірник SAB передається від основного потоку до воркера через метод postMessage(), середовище виконання не виконує операцію клонування даних. Замість цього, воркер отримує посилання на той самий блок фізичної пам’яті, що й основний потік. Це дозволяє двом або більше потокам читати та записувати дані в одну й ту ж ділянку пам’яті без накладних витрат на серіалізацію, десеріалізацію та виділення додаткової RAM, що є критично важливим для обробки великих даних.

Сам по собі SAB не надає методів для маніпуляції даними; він виступає лише контейнером для «сирих» байтів. Для читання або запису двійкових даних використовують \textbf{типізовані масиви} (TypedArrays), які надбудовують над буфером так званий об’єкт «представлення» (view). Різні представлення дозволяють інтерпретувати одну й ту саму послідовність байтів по-різному:
\begin{itemize}
  \item Int8Array – як 32-бітні цілі числа зі знаком;
  \item Float64Array – як числа з плавоючою крапкою подвійної точності;
  \item Uint8Array – як 8-бітні цілі числа без знака.
\end{itemize}

У контексті цієї роботи, де основним завданням є обробка текстових даних, як основне представлення даних було обрано Uint8Array. Цей вибір зумовлюється природою вхідних даних та зручністю адресації окремих символів.
\begin{enumerate}
  \item Для мінімального представлення текстових даних, закодованих в UTF-8 (ASCII), достатньо інтерпретувати кожен символ як послідовність з 8 бітів. Використання представлень більшої розрядності призвело б до надлишкового використання пам’яті.
  \item Представлення в UInt8Array дозволяє ефективно звертатися до кожного окремого символа без додаткових обчислень зміщень за простою формулою Адреса = Початок + Індекс в масиві.
\end{enumerate}

Робота в багатопотоковому середовищі, де кілька воркерів мають одночасний доступ до спільної ділянки пам’яті, неминуче створює ризик конфліктів синхронізації. \textbf{Atomics} – це глобальний об’єкт JavaScript, який надає функціонал для виконання неподільних (атомарних) операцій в спільному просторі, такі як зчитування, запис, модифікація та логічні операції.

Проте, слід зазначити, що нюанси розробленої в цій роботі архітектури повністю виключають необхідність використання Atomics через специфічну стратегію розділення даних. Відповідно до DGST алгоритму, фаза Data Partitioning \secref{sec:partitioning} передбачає рівномірне нарізання основного масиву даних, збережених в SAB, на частини (спліти), які потім розподіляються між потоками. Як результат, кожен воркер отримує ізольовану ділянку пам’яті, яку він лише читає або модифікує локально. Таким чином, жодні два воркери не пишуть ту саму ділянку SAB, виключаючи можливість «стану гонитви».

\newpage

% =====================================================
% РОЗДІЛ 2
% =====================================================
\section{ПРОЕКТУВАННЯ ТА АРХІТЕКТУРА СИСТЕМИ}

\subsection{Адаптація архітектури DGST}
Оригінальний алгоритм DGST реалізований на платформі \textbf{Apache Spark}, яка є стандартом де-факто для розподіленої обробки великих даних. Більшість проміжних обчислень у Spark виконуються в оперативній пам’яті (in-memory підхід), що надає фреймворку численні переваги над конкурентами у швидкості, простоті використання, модульності та масштабованості~\cite{damji_introduction_2020}.

На високому рівні архітектура Spark-застосунку складається з керуючого вузла (Driver Node), який координує виконання завдань, та кластера виконавчих вузлів (Executor Nodes), що здійснюють паралельну обробку даних, збережених у розподіленій файловій системі (HDFS). Архітектура HDFS також наслідує модель «майстер-раб» (Master-Slave). Вона складається з одного головного вузла імен (NameNode), який керує метаданими файлової системи, та множини вузлів даних (DataNodes), які безпосередньо зберігають блоки інформації. HDFS організовує дані за принципом механічного поділу на блоки фіксованого розміру (зазвичай 64 МБ), які розділяються між вузлами кластера~\cite{apache_software_foundation_hdfs_nodate}. У типовому Spark-кластері виконавчі вузли зазвичай розміщуються на тих самих фізичних машинах, що й вузли даних, щоб забезпечити принцип локальності даних (Data Locality) і мінімізувати мережевий трафік. Проте, коли переміщення даних є неминучим (наприклад, під час етапу Shuffle або передачі результатів керуючому вузлу), система змушена виконувати процедуру серіалізації, що є невід'ємною платою за розподілену структуру.

Не дивлячись на застосовані оптимізації, вузьким місцем архітектури Spark залишається висока вартість I/O звернень до зовнішніх накопичувачів. Такі операції типово відбуваються під час робочого процесу і включають зчитування даних з HDFS або запис даних на жорсткий диск.

Натомість, запропонована в цій роботі архітектура переносить кластерну організацію Apache Spark на Node.js стек з використанням воркерів.  Між елементами оригінальної та поданої архітектур можна побудувати таке відображення:
\begin{itemize}
  \item Керуючий вузол (Driver Node) \textrightarrow\ Майстер-нода, або Головний потік виконання (Main Thread).
  \item Виконавчий вузол (Executor Node) \textrightarrow\ Воркер від worker\_threads.
  \item HDFS \textrightarrow\ SharedArrayBuffer.
  \item Фізичний блок даних в HDFS \textrightarrow\ Логічний спліт SharedArrayBuffer.
\end{itemize}

Незмінним для обох архітектур залишається MapReduce потік виконання. Node.js реалізація емулює три ключові фази фреймворку: Map, Shuffle, Reduce – використовуючи програмні засоби, специфічні для цієї мови програмування. Загальна схема архітектури представлена на \figref{fig:png-4}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{images/Архітектура Node.js застосунку.png}
  \caption{Архітектура Node.js застосунку}
  \label{fig:png-4}
\end{figure}

Така структурна трансформація дозволяє зберегти перевірену часом логіку масштабування алгоритму DGST, але фундаментально змінює фізичну модель доступу до даних. Заміна розподіленої файлової системи (HDFS) на область спільної пам’яті (SharedArrayBuffer) дозволяє усунути накладні витрати на серіалізацію та мережеву передачу даних, притаманні Spark. Завдяки цьому архітектура переходить від моделі з інтенсивним вводом-виводом (I/O-bound) до моделі з ефективним використанням пам’яті (Memory-bound), що створює підґрунтя для оптимізації етапів MapReduce у середовищі Node.js.

\subsection{Стратегія управління пам'яттю}

Як згадувалося раніше, реалізація алгоритму DGST у середовищі Node.js є моделлю, продуктивність якої критично обмежена обсягом доступної оперативної пам’яті (Memory-bound). Така архітектурна специфіка зумовлює необхідність розробки ефективної стратегії керування ресурсами RAM. Відсутність чітких механізмів контролю навантаження неминуче призведе до критичної відмови системи внаслідок вичерпання пам’яті (Out-of-Memory error).

Центральним елементом стратегії є використання єдиного об’єкта Shared\-ArrayBuffer. Для всієї сукупності вхідних рядків буфер формується одноразово при ініціалізації програми з виділенням додаткових байтів на розмежувальні та термінальний символи. При передачі буфера між потоками дані не дублюються, реалізуючи притаманий SAB принцип нульового копіювання (Zero-Copy) та знімаючи накладні витрати на серіалізацію та десеріалізацію.

Подібно до Apache Spark, головний потік системи механічно нарізає SharedArrayBuffer на рівномірні спліти, обмежені парою індексів початку й логічного завершення у спільному буфері. На відміну від чистого фізичного кінця, логічний кінець включає «хвіст» — додаткові байти, що перекривають сусідній спліт і гарантують, що жоден S-префікс не буде обірваний на межі під час паралельного аналізу~\cite{zhu_dgst_2019}.

Критичним параметром для стабільності DGST алгоритму є ліміт пам’яті $F_m$, який визначає максимальний розмір піддерев, що будується в пам’яті воркера. Для обрахунку ліміту застосовується гібридна  евристика, яка враховує і апаратні обмеження виконавця, і розмір вхідних файлів.

Система динамічно встановлює ліміт пам’яті на основі даних про обсяги  доступної оперативної пам’яті та кількість логічних ядер процесора. Для запобігання аварійному завершенню процеса внаслідок OOM, лише 70\% вільної RAM вважаються доступними для задачі. Такий коефіцієнт обумовлений загальноприйнятими  практиками конфігурування високонавантажених систем, де ОС рекомендується залишати 20-30\% пам’яті на системні виклики та процеси~\cite{apache_software_foundation_tuning_nodate}. До того ж, лише 40\% цієї пам’яті відводяться на зберігання вузлів суфіксного дерева, компенсуючи накладні витрати на створення проміжних структур і V8 isolate для кожного екземпляру воркера.

Фінальне значення $F_m$ задається відношенням:
\begin{equation}
  F_m=\frac{memoryPerExecutor}{bytesPerSuffix,}
\end{equation}
де параметр $bytesPerSuffix \approx 20$ байтів. Хоча об’єкти в середовищі JavaScript мають більший фізичний розмір через системні метадані~\cite{sheludko_pointer_2020, bruni_fast_2017}, у даній моделі це число використовується як коефіцієнт логічної питомої ваги.

Така стратегія «оптимістичного калібрування» є безпечною завдяки тому, що сумарний обсяг пам'яті, який реально алокується під структури дерева, становить 28\% від фактично вільної RAM. Це дозволяє поєднувати зручність високорівневої об'єктної моделі JavaScript із високою продуктивністю алгоритму, уникаючи надмірної фрагментації піддерев.

Нарешті, для досягнення балансу в системі, значення $F_m$ утримується в межах від $50\ 000$ до $\frac{FileSize}{50}$. Таке обмеження виконує подвійну функцію: нижня межа захищає від створення надто малих завдань, де витрати на запуск воркера перевищують час самих обчислень, а верхня межа гарантує, що навантаження буде розподілено між потоками навіть при обробці надвеликих масивів даних.

\subsection{Алгоритмічні етапи реалізації}

Цей підрозділ окреслює основні етапи роботи алгоритму DGST, адаптованого під архітектуру спільної пам'яті. Процес обробки даних у розробленій системі розділений на чотири основні фази, що імітують потік виконання MapReduce.

\begin{enumerate}
  \item \textit{Фаза ініціалізації та попередньої обробки} \label{sec:partitioning}.

    Першим кроком є підготовка середовища та вхідних даних для паралельної обробки. Файлова система зчитує вхідні рядки та передає їх до Основного потоку для конкатенації у суперрядок. Він популює попередньо зарезервовану у пам’яті ділянку під SharedArrayBuffer з виділенням  окремих байтів під розмежувальні символи та термінальний символ наприкінці.
    Додатково, Основний потік керує динамічним визначенням кількості воркерів та обчисленням порогового значення $F_m$. У тому ж місці одноразово створюється пул для обрахованої кількості воркерів, усуваючи накладні витрати на керування їхнім життєвим циклом.

    Подальший етап передбачає рівномірне нарізання сформованого SAB на фрагменти, які називатимемо сплітами. Спліт не зберігає повний підрядок у нативному вигляді; його межі визначають індекс початку, фізичного і логічного закінчення.  Щоб жоден префікс не обірвався на межі, логічне закінчення розширюється на хвіст, але не виходить за фізичну довжину SAB.  Формування сплітів завершує підготовчу фазу потоку виконання.

  \item \textit{Фаза ітеративного розбиття на S-префікси.} \label{sec:iterative}

    Метою цього етапу є пошук такого набору S-префіксів довжиною ковзного вікна $windowSize$, щоб частота кожного унікального префікса не перевищувала встановлений ліміт $F_m$. Це гарантує, що будь-яке піддерево, побудоване на основі такого префікса, вміститься в оперативну пам'ять окремого воркера.

    Процес розбиття реалізовано як ітеративний цикл, що триває до досягнення умови $R = \varnothing$, де $R$ — множина «проблемних» префіксів, частота яких все ще перевищує поріг $F_m$. Кожна ітерація цієї фази включає наступні кроки:

    \begin{enumerate}
      \item \textbf{Паралельне сканування (Map).} Основний потік розподіляє між воркерами спліти SharedArrayBuffer, розширені на хвіст довжиною $windowSize \ - 1$. Виконавчі вузли отримують параметри вікна та фільтр префіксів, після чого здійснюють обхід буфера методом ковзного вікна. Для оптимізації обчислень кожен воркер будує локальний \textbf{частотний бор} (\textbf{Frequency Trie}). Використання цієї ієрархічної структури дозволяє ефективно групувати спільні префікси та виконувати підрахунок частот входжень за один прохід по тексту, мінімізуючи витрати оперативної пам'яті~\cite{zhu_dgst_2019}.

      \item \textbf{Тасування (Shuffle).} Головним завданням даного етапу є логічне групування локальних результатів за ключовими ознаками — унікальними S-префіксами. Для забезпечення детермінованості розподілу даних використовується механізм хешування: для кожного S-префікса обчислюється хеш-код, що гарантує спрямування всіх його входжень, виявлених різними воркерами, до єдиного обчислювального контексту.

      \item \textbf{Глобальна агрегація (Reduce).} Воркери повертають Основному потоку лише компактні об'єкти з локальною статистикою частот. Головний потік агрегує ці дані, формуючи глобальну картину розподілу суфіксів.

      \item \textbf{Перевірка умови зупинки.} На основі отриманої карти частот Основний потік будує фінальне частотний бор і аналізує його на предмет «проблемних» префіксів:
        \begin{itemize}
          \item Префікси, частота яких $\le F_m$, заносяться до множини валідних префіксів $P$.
          \item Префікси з частотою $> F_m$ заносяться до множини «проблемних» префіксів $R$.
          \item Якщо $R \ne \varnothing$, значення $windowSize$ збільшується на $window\-StepSize$, і цикл повторюється лише для сегментів даних, що відповідають префіксам з $R$.
          \item Якщо $R = \varnothing$, цикл зупиняється. Основний потік відсікає в частотному борі надлишкові гілки і формує фінальну карту частот префіксів.
        \end{itemize}
    \end{enumerate}

  \item \textit{Фаза розподілу завдань. }

    Ключовим завданням даного етапу є запобігання виникненню «вузьких  місць» (bottlenecks), що спричинені нерівномірним розподілом обчислювального навантаження між воркерами. Цю проблему вирішує комбінований підхід на основі двох алгоритмів: \textbf{Bin-Packing} та \textbf{Number Partitioning}. Їхня спільна робота спрямована на формування мінімально необхідної кількості груп завдань, де сумарна частота S-префіксів у кожній групі є максимально наближеною. Оскільки кількість груп завдань часто перевищує кількість доступних виконавчих вузлів, їхня паралельна обробка виконується послідовно по раундах. Такий підхід забезпечує рівномірне навантаження всіх потоків виконання та синхронне завершення обробки даних.

  \item \textit{Фаза побудови піддерев.}

    У результаті завершення фази розподілу навантаження кожен воркер отримує індивідуальний пакет завдань, що складається з набору валідних S-префіксів. Кожен префікс із цього набору є коренем майбутнього суфіксного піддерева, яке гарантовано вміщується в оперативну пам’ять окремого воркера. Принцип побудови піддерев базується на методі SALA (Suffix Array + LCP Array).

    \textbf{Суфіксний масив (SA)} є фундаментальною структурою даних, що впорядковує всі суфікси вхідного рядка у лексикографічному порядку. Оскільки операція сортування такого великого масиву є найбільш ресурсомісткою частиною алгоритму, для її прискорення використовується структура \textbf{LCP-Range} — трійка, яка зберігає інформацію про вже знайдені спільні частини рядків (Longest Common Prefix, найдовший спільний префікс). Це дозволяє реалізувати LCP-свідоме сортування, де суфікси порівнюються не з нуля, а зі зміщенням у довжину спільного початку, що значно економить ресурси CPU та I/O.

    Після сортування воркер розраховує LCP для кожної пари сусідніх елементів у масиві SA. Ці значення визначають глибину вкладеності та точки розгалуження майбутнього дерева. На основі готових масивів SA та LCP воркер будує піддерево за один лінійний прохід. Використовується допоміжний стек для відстеження поточного шляху від кореня. Нові вузли та листи додаються або розрізають існуючі ребра у точках, вказаних значеннями LCP.
\end{enumerate}

Отже, після завершення обчислень Основний потік отримує результати побудови всіх груп завдань. Сукупність цих локальних піддерев утворює розподілене узагальнене суфіксне дерево. Завдяки ітеративному розбиттю та паралельній побудові, отримана структура є повністю охоплює множину суфіксів усіх вхідних рядків, що робить її готовою до практичного використання у прикладних задачах.

\newpage

% =====================================================
% РОЗДІЛ 3
% =====================================================
\section{ПРОГРАМНА РЕАЛІЗАЦІЯ}

\subsection{Структури даних та низькорівнева організація пам’яті}

Програмна реалізація алгоритму DGST у середовищі Node.js базується на гібридній моделі управління даними, що поєднує низькорівневу оптимізацію доступу до тексту та високорівневу об’єктну логіку JavaScript. Ключовим інженерним викликом став пошук компромісу між зручністю використання абстракцій JavaScript, які значно спрощують роботу зі складними ієрархічними структурами,  та накладними витратами пам’яті, притаманними об’єктам двигуна V8.

Для розв’язання цієї задачі було прийнято стратегічне рішення: використовувати SharedArrayBuffer як єдине незмінне джерело істини для вхідних даних, тоді як усі проміжні структури (частотні бори, мапи префіксів та вузли дерева) реалізувати у вигляді динамічних об’єктів JavaScript. Такий підхід дозволив зберегти гнучкість розробки та використовувати ефективні вбудовані структури, як Map, ціною свідомого виділення більшого обсягу RAM під метадані. Стабільність цієї моделі забезпечується за рахунок жорсткої стратегії резервування пам’яті.

Програмно низькорівневий підхід імплементує процедура формування суперрядка з вхідних даних. Його створення починається з послідовного копіювання байтових масивів кожного вхідного файлу у спільний буфер. Між файлами вставляється розмежувальний символ \lstinline|U+E000| (який для зручності позначатимемо $\#$), а наприкінці додається термінальний \lstinline|U+E001| ($\$$). Обидва символи походять із \textbf{приватної зони Unicode} (\textbf{Private use area})~\cite{microsoft_private_2024}, тому гарантовано не зустрінуться у робочих текстах і не порушать лексикографічний порядок стандартних UTF-8 послідовностей при сортуванні суфіксного масива. Це означає, що всі подальші обчислення можуть оперувати буфером без перевірки на конфлікти з діючим алфавітом. Межі сплітів формуются рівно за індексами тих байтів, де лежать \lstinline|U+E000/U+E001|.

На базі цього низькорівневого фундаменту формується набір високорівневих проміжних структур, які керують логікою ітерацій та побудови піддерев. Представником такої структури є частотний бор (Frequency Trie), який реалізує рекурсивну ієрархію вузлів. Кожна нода бору інкапсулює лічильник частоти (\lstinline|frequency|), булевий індикатор завершеності префікса (\lstinline|isLeaf|) та структуру Map, що забезпечує швидкий доступ до дочірніх вузлів за ключами-символами. Коли обхід сформованного частотного бору не виявляє невалідних префіксів, ресурсомістке частотне дерево згортається до компатного представлення у вигляді масиву вкладених об'єктів \lstinline|{ prefix, frequency, length }|.  Це забезпечує перехід від фази розбиття до фази розподілу завдань з максимальною ефективністю використання пам'яті.
Після стабілізації множини префіксів фаза планування перетворює її на набір груп, де кожен елемент — це структура \lstinline|{ id, prefixes, totalFrequency }|. Індекс групи визначаює адресата (воркера) для передачі на побудову піддерева. Жодні дані не копіюються завдяки дескрипторному підходу: \lstinline|prefixes| містить посилання на ті самі об'єкти, що повернув ітеративний алгоритм.

Етап побудови піддерев використовує компактні проміжні структури, які уникають копіювання тексту завдяки роботі з числовими індексами в SharedArrayBuffer. Основні структури — це cуфіксний масив, що містить лише позиції початку кожного суфікса, та LCP-Range, кожен з яких зберігає зміщення спільного префікса, символ розбіжності та короткий 32-символьний фрагмент для швидких порівнянь. Такий формат дозволяє виконувати сортування методом LCP-Merge та будувати структуру дерева без перевищення ліміту пам'яті.

Готове дерево зберігається у вигляді двох масивів: вузлів (\lstinline|nodes|) та ребер (\lstinline|edges|). Кожен вузол — це простий об'єкт із числовим ідентифікатором, глибиною від кореня та типом (корінь, внутрішній вузол або листок).  Листки додатково містять інформацію про джерело: номер файлу та позицію суфікса всередині нього. Ребра описуються лише парою чисел — початком і кінцем діапазону в глобальному буфері. Завдяки тому, що замість реальних підрядків зберігаються тільки їхні координати в спільній пам'яті, система може обробляти десятки тисяч вузлів у межах одного воркера без вичерпання ресурсів. Приклад реалізації структур наведено на ~\schemaref{lst:node_example}.

\begin{lstlisting}[language=JavaScript, caption={Приклад об'єктної структури вузла та ребра}, float=t, label={lst:node_example}]
const rootNode = {
  id: 0,
  depth: 0,
  type: 'root'
};

const internalNode = {
  id: 5,
  depth: 12,
  type: 'internal'
};

const leafNode = {
  id: 42,
  depth: 87,
  type: 'leaf',
  suffixStart: 1523,
  stringId: 2,
  stringName: 'file2.txt',
  localIndex: 245
};

const edge = {
  from: 5,
  to: 42,
  start: 1523,
  end: 1610
};
\end{lstlisting}

Підсумовуючи, обрана гібридна модель дозволяє ефективно керувати життєвим циклом об’єктів. Оскільки всі проміжні структури існують лише протягом виконання конкретної фази або раунду, збирач сміття (Garbage Collector) двигуна v8 може вчасно звільняти пам’ять після завершення роботи воркера. Водночас основний масив даних у SharedArrayBuffer залишається незмінним і доступним для всіх потоків, що забезпечує стабільність системи при масштабуванні вхідного датасету до мільйонів рядків.

\subsection{Реалізація Майстер-ноди (Main Thread)}

Головний потік у розробленій системі виконує роль оркестратора, що централізовано координує виконання алгоритму DGST. На відміну від виконавчих вузлів, які здійснюють CPU-інтенсивні обчислення, Майстер-нода працює в основному циклі подій і не виконує блокуючих операцій. Її завдання – ініціалізувати SharedArrayBuffer, запустити пул воркерів, розподілити завдання та дочекатися відповідей, не блокуючи основний потік. Програмна реалізація зосереджена у модулі \lstinline|dgst-engine.js|, який експортує асинхронну функцію \lstinline|buildDGST|.

\begin{enumerate}
  \item \textit{Програмна реалізація пулу воркерів.}

    Для керування воркерами створено окремий клас \lstinline|WorkerPool|, який інкапсулює логіку ініціалізації, розподілу завдань та завершення роботи потоків. У конструкторі класу створюється масив екземплярів \lstinline|Worker|, кожен з яких ініціалізується шляхом передачі до нього:

    \begin{lstlisting}[language=JavaScript, caption={Ініціалізація воркерів у пулі}]
    const worker = new Worker(this.workerPath, {
        workerData: { workerId: i }
    })
    this.workers.push(worker)
    \end{lstlisting}

    Критично важливим рішенням є створення воркерів один раз при ініціалізації та їхнє перевикористання протягом усіх фаз алгоритму. Це мінімізує накладні витрати на створення та знищення потоків операційної системи, які є значно більшими порівняно з передачею повідомлень через \lstinline|postMessage|. Воркери зберігаються у масиві \lstinline|this.workers|, а розподіл завдань здійснюється за принципом round-robin через лічильник \lstinline|nextWorkerIndex|, який циклічно інкрементується після кожного виклику \lstinline|execute()|.

  \item \textit{Керування фазами та асинхронна синхронізація.}

    Оскільки архітектура Node.js є неблокуючою, взаємодія з воркерами відбувається в асинхронному режимі. Це означає, що Майстер-нода не зупиняє виконання всього алгоритму під час очікування відповіді від потоків, а продовжує обробку подій. Для координації обчислювальних фаз (наприклад, щоб не розпочати агрегацію частот до того, як усі воркери завершать підрахунок префіксів) у системі реалізовано механізм асинхронної синхронізації.

    Програмним інструментом для реалізації цього механізму обрано \textbf{Promise} – спеціальний об’єкт, що дозволяє керувати станом асинхронної операції через \lstinline|resolve| (успішне завершення) та \lstinline|reject| (виникнення помилки)~\cite{keller_discover_nodate}. Логіка взаємодії з потоками інкапсульована у методі \lstinline|execute(message)| класу \lstinline|WorkerPool|. Він ініціалізує Promise та реєструє обробник подій на порті зв’язку, що дозволяє через відповідні функції повертати результати успішних обчислень або обробляти виключні ситуаці, забезпечуючи загальну відмовостійкість.

    \begin{lstlisting}[language=JavaScript, caption={Реалізація механізму асинхронної синхронізації}]
    execute(message) {
        return new Promise((resolve, reject) => {
            const worker = this.workers[this.nextWorkerIndex]
            this.nextWorkerIndex = (this.nextWorkerIndex + 1) % this.workers.length

                const onMessage = (msg) => {
                    worker.off('message', onMessage)
                    worker.off('error', onError)
                    if (msg.type === 'success') {
                        resolve(msg.result)
                    } else if (msg.type === 'error') {
                        reject(new Error(msg.error))
                    }
                }

                worker.once('message', onMessage)
                worker.once('error', onError)
                worker.postMessage(message)
            })
        }
    \end{lstlisting}

    Для розподілу завдань на будь-яку фазу (Map, Reduce або побудова піддерев) Майстер-нода створює масив Promise для кожного завдання та використовує \lstinline|Promise.all()| для очікування завершення всіх воркерів. Це реалізує програмний бар'єр: головний потік не переходить до наступної фази, поки всі воркери не повернуть свої результати.

  \item\textit{Керування ітеративним циклом.}

    Центральною функцією координації є \lstinline|processIteratively()|, яка реалізує ітеративне збільшення ковзаючого вікна з умовою виходу на основі стану частотного бору. Майстер-нода підтримує два критичні змінні стану: \lstinline|finalPrefixes| (акумулятор валідних префіксів) та \lstinline|targetPrefixes| (фільтр для наступної ітерації). Структура циклу представлена нижче:

    \begin{lstlisting}[language=JavaScript, caption={Структура ітеративного циклу координації}]
    while (true) {
        config.windowSize = windowSize

            const mapResults = await executeMapRound(updatedSplits, targetPrefixes)
            const partitions = shuffleByKey(mapResults, config.numWorkers)
            const reduceResults = await executeReduceRound(partitions)

            const mergedTrie = buildTrieFromReduceResults(reduceResults)
            const { accepted, needsExtension } = mergedTrie.partitionByFrequency(
                config.memoryLimit,
                windowSize
            )

            accepted.forEach(sp => {
                finalPrefixes.push({ prefix: sp.prefix, frequency: sp.frequency })
            })

            if (needsExtension.length === 0) {
                break
            }

            targetPrefixes = new Set(needsExtension.map(sp => sp.prefix))
            windowSize += windowStepSize
        }
    \end{lstlisting}

    На кожній ітерації виконується послідовність Map/Shuffle/Reduce, після чого результати агрегуються у глобальний частотний бор через \lstinline|buildTrieFromReduceResults()|. Метод \lstinline|partitionByFrequency()| класифікує префікси за критерієм частоти: ті, що вміщуються в ліміт пам'яті $F_m$, додаються до \lstinline|finalPrefixes|, а «проблемні» формують множину \lstinline|targetPrefixes| для наступної ітерації. На наступній ітерації воркери отримують фільтр \lstinline|targetPrefixes|, що мінімізує обсяг обчислень.

    По завершенню ітеративного циклу Майстер-нода викликає планувальник \lstinline|allocateTaskGroups()|, який розподіляє префікси на групи за алгоритмом best-fit bin packing, та запускає раунди побудови піддерев послідовно, використовуючи по завершенню той самий \lstinline|Promise.all()|.

\end{enumerate}

\subsection{Реалізація Виконавчих нод (Workers)}
Виконавчі ноди, або воркери, є автономними обчислювальними одиницями, які виконують CPU-інтенсивні операції в асинхронному режимі. Воркери зосереджені виключно на обробці даних: сканування буфера, підрахунок частот префіксів, агрегація результатів та побудова суфіксних піддерев. Програмна реалізація зосереджена у модулі \lstinline|worker-node.js|, який використовує API \lstinline|worker_threads| для комунікації з головним потоком.

Воркери працюють в подіє-орієнтованій моделі, реагуючи на повідомлення від Майстер-ноди через порт зв’язку. Центральним елементом комунікації є обробник події \lstinline|message|, який реалізує диспетчеризацію задач на основі поля \lstinline|phase|: ‘divide’ для Map-фази, ‘reduce’ для Reduce-фази та ‘divide’ для фази побудови піддерев:

\begin{lstlisting}[language=Javascript, caption=Диспетчеризація завдань воркера]
parentPort.on('message', async (event) => {
    try {
        const { phase, sharedBuffer, split, windowSize, partition, group, boundaries } = event

        if (phase === 'divide') {
          ...
        } else if (phase === 'reduce') {
          ...
        } else if (phase === 'subtree') {
          ...
        } else {
            throw new Error(`Unknown phase: ${phase}`)
        }
    } catch (error) {
        parentPort.postMessage({
            type: 'error',
            error: error.message || 'Unknown error',
            stack: error.stack
        })
    }
})
\end{lstlisting}

Така архітектура дозволяє воркеру обробляти різні типи завдань без перезапуску потоку, мінімізуючи накладні витрати на ініціалізацію. Кожна фаза отримує специфічний набір параметрів через деструктуризацію об'єкта події, виконує відповідні обчислення та повертає результат через \lstinline|parentPort.postMessage()| з типом \lstinline|success|, якщо обробка пройшла успішно.

Критично зазначити, що специфіка обчислювальних завдань воркерів передбачає роботу з нативним рядковим поданням даних, а не з байтовими масивами.  Це створює значні накладні витрати при використанні SharedArrayBuffer через необхідність постійного декодування UTF-8 у рядки. Процес декодування є двоетапним: спочатку над SAB створюється представлення Uint8Array для доступу до окремих байтів, а потім ці байти передаються об’єкту  TextDecoder для їх інтерпретації як UTF-8 та перетворення у JavaScript-рядок.

Оскільки воркер обробляє десятки завдань протягом свого життєвого циклу, багаторазове декодування одного й того самого буфера призводить до надмірного споживання RAM. Саме тому, для уникнення надлишкових обчислень та неефективного використання пам'яті, для мінімізації цих витрат реалізовано механізм кешування декодованого вмісту буфера:

\begin{lstlisting}[language=JavaScript, caption={Кешування декодованого тексту}]
let cachedSharedBuffer = null
let cachedDecodedText = null

function getSharedText(sharedBuffer) {
    if (cachedSharedBuffer === sharedBuffer &&
        typeof cachedDecodedText === 'string') {
        return cachedDecodedText
    }

    const view = decodeSharedBuffer(sharedBuffer)
    cachedDecodedText = textDecoder.decode(view)
    cachedSharedBuffer = sharedBuffer
    return cachedDecodedText
}
\end{lstlisting}

Воркер зберігає посилання на останній оброблений буфер та його декодовану версію у змінних \lstinline|cashedSharedBuffer| та \lstinline|cashedDecodedText| відповідно. При отриманні нового завдання виконується перевірка ідентичності накладних витрат на повторне декодування. Якщо буфер не змінився, повертається кешована версія, уникаючи повторного декодування. Це особливо критично для фази побудови піддерев, де кожен воркер може обробляти десятки груп префіксів послідовно з одним і тим самим буфером.

З урахуванням цього, розглянемо специфіку реалізації кожної фази: Map, Reduce та побудови піддерев.

\begin{enumerate}

  \item\textit{Реалізація фази Map (divide).}

    У фазі Map воркер отримує дескриптор спліта, що визначає межі обробки у SharedArrayBuffer. Центральним елементом цього етапу є функція \lstinline|computeSPrefixes()|, яка виконує сканування методом ковзного вікна. На кожній позиції витягується підрядок довжини \lstinline|windowSize|, декодується та додається до локального частотного бору. Якщо Майстер-нода передала параметр \lstinline|targetPrefixes|, воркер обробляє лише префікси з цієї множини, що прискорює повторні ітерації. Результатом є масив об'єктів \lstinline|{ prefix, frequency, length }|.

  \item\textit{Реалізація фази Reduce. (reduce)}

    У фазі Reduce воркер отримує партицію – масив S-префіксів від різних воркерів з однаковим хеш-ключем. Завдання воркера полягає у тому, щоб агрегувати у Map \lstinline|aggregated| частоти однакових префіксів. Воркер ітерує по партиції: якщо префікс вже існує у Map, його частота інкрементується, інакше створюється новий запис. Результат конвертується у масив та повертається Майстер-ноді.

  \item\textit{Реалізація фази побудови піддерев (subtree).}

    На цьому етапі воркер отримує групу префіксів і межі файлів, щоб відновити контекст появ для індексації суфіксів. Функція \lstinline|getSharedText()| повертає декодований текст, після чого \lstinline|buildSubTreeForPrefix()| проходить три кроки: знаходить усі входження префікса за алгоритмом KMP, формує суфіксний і LCP масиви і відтворює дерево за один прохід зі стеком. На виході воркер повертає опис піддерева з вузлами, ребрами, суфіксним масивом і метаданими Майстер-ноді.
\end{enumerate}

У результаті воркер поводиться як спеціалізований сервіс: отримує вказівку на фазу, читає (або повторно використовує) спільний буфер і повертає уніфікований результат, залишаючи головному потоку лише координацію.

\newpage
% =====================================================
% РОЗДІЛ 4
% =====================================================
\section{ЕКСПЕРИМЕНТАЛЬНЕ ДОСЛІДЖЕННЯ ТА АНАЛІЗ ЕФЕКТИВНОСТІ}

Для оцінки продуктивності розробленої системи було проведено серію експериментальних запусків. Тестування виконувалося на обчислювальній машині з наступними технічними характеристиками: процесор AMD Ryzen 5 7460HS, 12 логічних ядер, 16 ГБ оперативної пам'яті, під управлінням ОС Windows 11. Всі вимірювання проводилися у середовищі виконання Node.js v24.12.0.

Важливою особливістю конфігурації експерименту стало використання 12 виконавчих нод. Такий вибір зумовлений архітектурою процесора: призначення одного воркера на кожне логічне ядро дозволяє досягти максимального використання обчислювальних потужностей без накладних витрат на контекстне перемикання потоків (context switching).

Об’єктом дослідження виступив текстовий масив обсягом 2 млн рядків, який був розділений на чотири вибірки по 0.5 млн (~7 МБ), 1.0 млн (~13 МБ), 1.5 млн (~20 МБ) та 2.0 млн рядків (~25 МБ). Методика тестування передбачала проведення 12 контрольних запусків для кожного набору даних.  Критеріями оцінки ефективності виступали: середній час обробки, пікове споживання RAM (MemoryLimit), кількість виявлених префіксів (SPrefixes) та кількість ітерацій головного циклу обробки, яка відображає кількість кроків алгоритму до досягнення фінального результату.

Результати замірів зафіксовано у ~\tabref{tab:results}:

\begin{table}[h!]
  \centering
  \renewcommand{\arraystretch}{1.5} % Збільшує висоту рядків для кращої читабельності
  \begin{tabular}{|l|c|c|c|c|}
    \hline
    \textbf{Кількість рядків} & \textbf{Сер. час (с)} & \textbf{SPrefixes} & \textbf{MemoryLimit} & \textbf{Ітерації} \\ \hline
    0.5 млн                   & 8.396586              & 608                         & 144361                        & 2                 \\ \hline
    1.0 млн                   & 15.406581             & 736                         & 282613                        & 2                 \\ \hline
    1.5 млн                   & 19.380307             & 788                         & 418141                        & 3                 \\ \hline
    2.0 млн                   & 25.929663             & 849                         & 526693                        & 3                 \\ \hline
  \end{tabular}
  \caption{Результати замірів продуктивності системи}
  \label{tab:results}
\end{table}

Аналіз результатів демонструє пряму залежність між обсягом даних та споживанням ресурсів. При збільшенні кількості рядків у чотири рази (з 0.5 млн до 2.0 млн) показник MemoryLimit зріс лише у ~3.6 раза (з 144 361 до 526 693 одиниць). Оскільки приріст пам’яті відстає від приросту обсягу даних (коли даних стало в 4 рази більше, показник пам'яті зріс лише в 3.64 раза), це об’єктивно підтверджує ефективність використання SharedArrayBuffer: 12 воркерів працюють з єдиним спільним масивом у пам’яті, не створюючи власних копій даних, що зазвичай призвело б до набагато стрімкішого зростання показників.

Найбільш вагомим доказом ефективності кешування є порівняння результатів для 1.0 млн та 1.5 млн рядків. Попри те, що обсяг даних зріс на 50\% і одночасно збільшилася кількість ітерацій головного циклу з 2 до 3, загальний час виконання збільшився лише на 4 секунди (з 15.4 с до 19.4 с). Якби воркери щоразу заново декодували один і той самий буфер для кожної нової ітерації, час обробки зростав би набагато швидше. Той факт, що додаткова ітерація майже не сповільнила систему, доводить: воркери використовують уже готовий декодований рядок із кешу.

Продуктивність системи підтверджується і підсумковою швидкістю на максимальному обсязі у 2 млн рядків, яка становить 77 132 рядки за секунду (2 000 000 рядків / 25.9 с). Навіть при зростанні кількості знайдених префіксів до 849 одиниць, що збільшує навантаження на етапі агрегації результатів, система зберігає високу продуктивність.

\newpage

% =====================================================
% ВИСНОВКИ
% =====================================================
\section*{ВИСНОВКИ}
\addcontentsline{toc}{section}{ВИСНОВКИ}

% =====================================================
% ВИКОРИСТАНІ ДЖЕРЕЛА
% =====================================================
\newpage
\printbibliography[
  heading=bibintoc,               % Додає список у зміст (table of contents)
  title={ВИКОРИСТАНІ ДЖЕРЕЛА}     % Власний заголовок великими літерами
]

\end{document}
